# ============================================================================
# Voice Stack Docker Compose Configuration
# ============================================================================
# Run both ASR and TTS services from a single unified Docker image
#
# Usage:
#   docker-compose up -d              # Start both services
#   docker-compose up -d asr          # Start only ASR
#   docker-compose up -d tts          # Start only TTS
#   docker-compose logs -f            # View logs
#   docker-compose down               # Stop services
#
# Build:
#   docker-compose build              # Build production image
# ============================================================================

services:
  # -------------------------------------------------------------------------
  # ASR Service (Automatic Speech Recognition)
  # -------------------------------------------------------------------------
  asr:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        BUILDKIT_INLINE_CACHE: 1
    image: voice-stack:latest
    container_name: voice-stack-asr
    restart: unless-stopped

    environment:
      # Service configuration
      SERVICE_MODE: asr

      # Server settings
      ENV: production
      LOG_LEVEL: INFO
      HOST: 0.0.0.0
      ASR_PORT: 5001

      # CORS (adjust for your needs)
      CORS_ORIGINS: "*"

      # ASR Engine settings
      ASR_ENGINE: faster-whisper
      ASR_DEVICE: cpu  # Change to 'cuda' if you have GPU
      ASR_MODEL: base
      ASR_COMPUTE_TYPE: int8

      # Performance tuning
      ASR_BEAM_SIZE: 5
      ASR_MAX_WORKERS: 4

      # Debugging (disable in production)
      DEBUGPY_ENABLE: "false"

    ports:
      - "5001:5001"

    volumes:
      # Model cache (persist downloaded models)
      - asr-models:/app/models
      # Optional: mount custom .env file
      # - ./.env:/app/.env:ro

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    # Resource limits (adjust based on your system)
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G

    # GPU support (uncomment if using CUDA)
    # runtime: nvidia
    # environment:
    #   - NVIDIA_VISIBLE_DEVICES=all
    #   - ASR_DEVICE=cuda

  # -------------------------------------------------------------------------
  # TTS Service (Text-to-Speech)
  # -------------------------------------------------------------------------
  tts:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        BUILDKIT_INLINE_CACHE: 1
    image: voice-stack:latest
    container_name: voice-stack-tts
    restart: unless-stopped

    environment:
      # Service configuration
      SERVICE_MODE: tts

      # Server settings
      ENV: production
      LOG_LEVEL: INFO
      HOST: 0.0.0.0
      TTS_PORT: 5002

      # CORS (adjust for your needs)
      CORS_ORIGINS: "*"

      # TTS Engine settings
      TTS_ENGINE: coqui
      TTS_DEVICE: cpu  # Change to 'cuda' if you have GPU
      TTS_MODEL: tts_models/multilingual/multi-dataset/xtts_v2

      # Audio settings
      TTS_SAMPLE_RATE: 24000
      TTS_MAX_CHARS: 180
      TTS_MIN_CHARS: 70
      TTS_RETRY_STEPS: 2

      # Language settings
      TTS_DEFAULT_LANG: en
      TTS_AUTO_LANG: "true"

      # Voices directory
      TTS_VOICES_DIR: /app/voices

      # Debugging (disable in production)
      DEBUGPY_ENABLE: "false"

    ports:
      - "5002:5002"

    volumes:
      # Model cache (persist downloaded models)
      - tts-models:/app/models
      # Voice samples for cloning
      - ./voices:/app/voices:ro
      # Optional: mount custom .env file
      # - ./.env:/app/.env:ro

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    # Resource limits (TTS is memory-intensive)
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '2.0'
          memory: 4G

    # GPU support (uncomment if using CUDA)
    # runtime: nvidia
    # environment:
    #   - NVIDIA_VISIBLE_DEVICES=all
    #   - TTS_DEVICE=cuda

# -----------------------------------------------------------------------------
# Volumes
# -----------------------------------------------------------------------------
volumes:
  # Persist downloaded models across container restarts
  asr-models:
    driver: local
  tts-models:
    driver: local

# -----------------------------------------------------------------------------
# Networks (optional: define custom network)
# -----------------------------------------------------------------------------
networks:
  default:
    name: voice-stack-network
    driver: bridge
